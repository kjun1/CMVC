{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801cad9a-4958-49a3-95fd-09afb1fd391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c411eaac-9518-48bf-97c2-acb2eee672ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_toml = toml.load(open('../config.toml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9fa17e-a7e0-4b5f-a2bb-749c9c8c99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = dict_toml[\"path\"][\"dataset\"][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636614fb-c6cc-4c79-9724-a371d0fa3094",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.read_table(image_path+\"/list_attr_celeba.txt\", header=0,sep=\" \", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc7da5e-adea-4142-a785-5ddb65466751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000001.jpg</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000002.jpg</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000003.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000004.jpg</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000005.jpg</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202595.jpg</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202596.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202597.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202598.jpg</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202599.jpg</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202599 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Male\n",
       "000001.jpg    -1\n",
       "000002.jpg    -1\n",
       "000003.jpg     1\n",
       "000004.jpg    -1\n",
       "000005.jpg    -1\n",
       "...          ...\n",
       "202595.jpg    -1\n",
       "202596.jpg     1\n",
       "202597.jpg     1\n",
       "202598.jpg    -1\n",
       "202599.jpg    -1\n",
       "\n",
       "[202599 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df[[\"Male\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3046071a-ef7d-4f0c-ba10-b3eb86a8c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../not_detected.txt', 'r')\n",
    "\n",
    "datalist = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95872457-8daa-44f9-9c71-476b169b4331",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [not i in datalist for i in image_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef0b170b-721c-41ea-89e2-f1a17948c6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000001.jpg   -1\n",
       "000002.jpg   -1\n",
       "000003.jpg    1\n",
       "000005.jpg   -1\n",
       "000007.jpg    1\n",
       "             ..\n",
       "202595.jpg   -1\n",
       "202596.jpg    1\n",
       "202597.jpg    1\n",
       "202598.jpg   -1\n",
       "202599.jpg   -1\n",
       "Name: Male, Length: 182367, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df[data][\"Male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b86dceab-b1a2-4d6e-a7c9-1da256d29d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VCC2SF1', 'VCC2TF2', 'VCC2SF2', 'VCC2SF4', 'VCC2SF3', 'VCC2TF1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../../voice/train/F/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fcb6c-197d-4bea-ad79-f1ca11794566",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(\"../../voice/train/F/VCC2SF1\"):\n",
    "    a = pd.read_pickle(\"../../voice/train/F/VCC2SF1/\"+i)\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559b925-a02f-4469-ab6b-99b8dd27db4e",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c795306-86ad-4bf3-9b2a-4f14e5b371f2",
   "metadata": {},
   "source": [
    "## transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0640eaf0-537c-4509-bcc0-0a1f36b638e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceTrans(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def norm_voice(self, array):\n",
    "        min = array.min()\n",
    "        array -= min \n",
    "    \n",
    "        max = array.max()\n",
    "        array /= max\n",
    "    \n",
    "        return array\n",
    "    \n",
    "    def cut(self, voice):\n",
    "        return voice[:, :voice.shape[1]-voice.shape[1]%4]\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        return self.cut(self.norm_voice(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "055b26da-92ba-4455-b4eb-06c825e6c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = pd.read_pickle(\"../../voice/train/VCC2SF1/10001.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5c47ec5-a1a0-4725-9df1-a5302738bad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 264)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = VoiceTrans()\n",
    "t(voice).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c3070-f124-427e-981d-1695aca21004",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13a47ca6-8f6a-459d-a61e-58ac1eee4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class VoiceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
