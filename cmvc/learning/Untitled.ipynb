{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f202c00b-acd4-4544-b52e-b6b2ca6b793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pyworld as pw\n",
    "import librosa\n",
    "import cv2\n",
    "\n",
    "from cmvc import *\n",
    "from cmvc.utils.data.dataset import PairDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953c45c8-141c-4ad8-bdd2-b06675129a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33932ed8-f559-454f-a1dd-bb0a9cab81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_toml = toml.load(open('/home/jun/Documents/CMVC/cmvc/config.toml'))\n",
    "\n",
    "image_path = pathlib.Path(dict_toml[\"path\"][\"dataset\"][\"processing\"][\"image\"])\n",
    "voice_path = pathlib.Path(dict_toml[\"path\"][\"dataset\"][\"processing\"][\"voice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21923710-9420-4a51-94f9-db99af96af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uttr_path = pathlib.Path(dict_toml[\"path\"][\"dataset\"][\"voice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4ab7bf-9e6e-488b-b43a-4b95b86bf27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PairDataset(voice_path=voice_path, image_path=image_path, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9a4b52-1d9c-4f39-b50a-158c4d261aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = PairDataset(voice_path=voice_path, image_path=image_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0730a01-9c86-4c27-9df9-309d9f29629b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31015]\n",
      "/home/jun/Documents/CMVC/voice/eval/VCC2SM3/30013.pkl\n"
     ]
    }
   ],
   "source": [
    "tmp = eval_data.__getitem__(idx=0, k=1)\n",
    "wav, img = tmp[0], tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086bd31c-a204-4ed9-9965-19eacc40c131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 36, 180])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a0ec52-45e0-415e-a69f-b51e5c0e58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_inv = dataset.voice_transform.inv_trans\n",
    "voice_trans = dataset.voice_transform.__call__\n",
    "image_inv = dataset.image_transform.inv_trans\n",
    "image_trans = dataset.image_transform.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c519512-0b43-43b8-a27a-9a76fcc6e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uttr_path = uttr_path/\"vcc2018_database_evaluation/vcc2018_evaluation\"/\"VCC2SF1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a87834e2-5573-48dd-80aa-6fd97bf03c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wav = list(uttr_path.iterdir())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcf5ea38-2a17-47a6-af28-20df875353ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display.Audio(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a363f9b-7412-455c-a0de-905da414c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = image_path / \"000085.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee2767d1-2fe4-4c71-996a-d35c4da74723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display.Image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d539c42f-a8d1-407c-939e-ef0d17c90fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ccc82af-423b-4cfa-81ef-a1b932d28fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = pathlib.Path('/home/jun/Documents/CMVC/checkpoint')\n",
    "checkpoint = torch.load(model_dir/(str(10).zfill(4)+\".cpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "022ffe11-d6a6-44be-8972-04430cc810fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(checkpoint['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09647276-3bed-45e2-8562-b1fb3e8d1b07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc455391-45fa-485f-8f6a-9ffb8974585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, voice, image,\n",
    "             device=\"cpu\"):\n",
    "    net.eval()\n",
    "    \n",
    "    x = voice.to(device)\n",
    "    y = image.to(device)\n",
    "    \n",
    "    return net.forward(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62dedfb1-cdb0-441f-a9ba-c1eb9d804579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx, fs = librosa.load(wav, sr=22050, dtype=np.float64)\\nmccs = librosa.feature.melspectrogram(y=x, sr=fs, n_mels=36)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x, fs = librosa.load(wav, sr=22050, dtype=np.float64)\n",
    "mccs = librosa.feature.melspectrogram(y=x, sr=fs, n_mels=36)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1bbb400-c238-441e-959b-fb8bbf4cbc96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nxx = torch.tensor([[voice_trans(mccs)]])\\nyy = torch.tensor(image_trans(cv2.imread(str(img))))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "xx = torch.tensor([[voice_trans(mccs)]])\n",
    "yy = torch.tensor(image_trans(cv2.imread(str(img))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7afcac-7ef8-4bfc-b7fa-eab2e971896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = wav\n",
    "yy = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "548e27da-9e8a-4fef-bf36-9e2e0a3abedf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (ue): UttrEncoder(\n",
       "    (uttr_enc_d1): CBGLayer(\n",
       "      (conv1): Conv2d(1, 16, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "      (conv2): Conv2d(1, 16, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (uttr_enc_d2): CBGLayer(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (conv2): Conv2d(16, 32, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (uttr_enc_d3): CBGLayer(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (uttr_enc_d4): Conv2d(32, 16, kernel_size=(9, 5), stride=(9, 1), padding=(0, 2))\n",
       "  )\n",
       "  (ud): UttrDecoder(\n",
       "    (uttr_dec_d1): DBGLayer(\n",
       "      (deconv1): ConvTranspose2d(8, 16, kernel_size=(9, 5), stride=(9, 1), padding=(0, 2))\n",
       "      (deconv2): ConvTranspose2d(8, 16, kernel_size=(9, 5), stride=(9, 1), padding=(0, 2))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (uttr_dec_d2): DBGLayer(\n",
       "      (deconv1): ConvTranspose2d(16, 16, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (deconv2): ConvTranspose2d(16, 16, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (uttr_dec_d3): DBGLayer(\n",
       "      (deconv1): ConvTranspose2d(16, 8, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (deconv2): ConvTranspose2d(16, 8, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (uttr_dec_d4): ConvTranspose2d(8, 2, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "  )\n",
       "  (fe): FaceEncoder(\n",
       "    (face_enc_d1): Sequential(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "      (lReLU): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (face_enc_d2): CBLLayer(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (face_enc_d3): CBLLayer(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (face_enc_d4): CBLLayer(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (face_enc_d5): CBLLayer(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (face_enc_d6): FlattenLayer()\n",
       "    (face_enc_d7): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (face_enc_d8): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=16, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fd): FaceDecoder(\n",
       "    (face_dec_d1): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (face_dec_d2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (face_dec_d3): ReshapeLayer()\n",
       "    (face_dec_d4): DBSLayer(\n",
       "      (deconv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (face_dec_d5): DBSLayer(\n",
       "      (deconv): ConvTranspose2d(128, 128, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (face_dec_d6): DBSLayer(\n",
       "      (deconv): ConvTranspose2d(128, 64, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (face_dec_d7): DBSLayer(\n",
       "      (deconv): ConvTranspose2d(64, 32, kernel_size=(6, 6), stride=(2, 2), padding=(4, 4))\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (face_dec_d8): Conv2d(32, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       "  (ve): VoiceEncoder(\n",
       "    (voice_enc_d1): CBGLayer(\n",
       "      (conv1): Conv2d(1, 32, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "      (conv2): Conv2d(1, 32, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (voice_enc_d2): CBGLayer(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (conv2): Conv2d(32, 64, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (voice_enc_d3): CBGLayer(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (voice_enc_d4): CBGLayer(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (voice_enc_d5): CBGLayer(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(4, 5), stride=(4, 1), padding=(0, 2))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(4, 5), stride=(4, 1), padding=(0, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (voice_enc_d6): CBGLayer(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "      (conv2): Conv2d(128, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (voice_enc_d7): Conv2d(64, 16, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a842863-92a2-46ef-8d3e-0b508478a246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8227e-08)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice_inv(xx).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9733b97-ece5-4770-afbc-60cbdd20f789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 36, 180])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fbc2e2e-fad2-4ca7-ae32-75366ad80a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#net.fe.face_encoder(yy)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f33e6f9-dede-4a9d-8966-a62a5e0cf0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.fe(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71067b44-ce91-43f0-9460-93e78b8781b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0628, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_net(net, xx, yy).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ba77d9e1-8e31-4272-9067-75ce14873f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_mccs_tensor = eval_data.voice_transform.inv_trans(eval_net(net, xx, yy)).squeeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b2c1a97-8613-4250-b629-a63c3d606572",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_mccs = conversion_mccs_tensor.detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9b72b163-b736-40cd-a441-31ad6f1abcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 180)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_mccs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "294aafe0-5be4-425c-8568-de0fc343d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mccs = xx.squeeze(0).squeeze(0).detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0bc42df5-18ba-4721-8ebf-e04d1393f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mccs_to_audio(mccs):\n",
    "    mccs = mccs.astype(\"float32\")\n",
    "    mccs += mccs.min()\n",
    "    S = librosa.feature.inverse.mel_to_stft(mccs)\n",
    "    y = librosa.griffinlim(S, dtype=np.float32)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9cba2411-d327-4a91-bc2d-81720708b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mccs_to_audio(conversion_mccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a6e467bd-f253-4978-a79d-e49db2bb5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ca8ea5cd-d53a-4392-8066-8b0524f0f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(\"conv.wav\", y, 22050, \"PCM_24\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
