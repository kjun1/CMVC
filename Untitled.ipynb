{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5402d452-d0f6-4bb1-b29b-ecdd2a627a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmvc import *\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf385a51-e0fb-40b4-8c7d-b48462b27e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278c37c0-aa21-44ce-917c-dbabef81e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a72772-7b43-468a-9f23-80593f040945",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "入力\n",
    "\n",
    "1: バッチサイズ\n",
    "\n",
    "2: channel\n",
    "\n",
    "3: mfcc_size(画像における縦)\n",
    "\n",
    "4: uttr_len(画像における横)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c98a547-9e99-416e-a9de-575f5e07e44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.ones((2,8))\n",
    "fd = FaceDecoder()\n",
    "fd(c).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d4dc7-c3fa-4340-aba1-d342b7c974d2",
   "metadata": {},
   "source": [
    "# train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5c34b0-a046-4639-8649-1adc3e907f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0182, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((2,1,36,24))\n",
    "y = torch.zeros((2,3,32,32))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "net.train()\n",
    "\n",
    "x = x.to(device) \n",
    "y = y.to(device)\n",
    "net.zero_grad()\n",
    "print(net.test(x, y))\n",
    "#loss = net.loss(x, y)\n",
    "#print(loss)\n",
    "#loss.backward()\n",
    "#optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d82342-7f19-4e02-9591-d81b0e1b1224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63fd2a3-e3ea-48b6-9ea5-3d2316bb9b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx = torch.ones((2,8,1,8))\\nfor i in range(x.size()[-1]):\\n    print(x[:,:,:,i].squeeze().size())\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x = torch.ones((2,8,1,8))\n",
    "for i in range(x.size()[-1]):\n",
    "    print(x[:,:,:,i].squeeze().size())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57109904-7276-4afc-8374-2e9c5daa433b",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cccdda1-5124-4174-b5da-15d8094283e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 36, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((2,1,36,16))\n",
    "y = torch.ones((2,3,32,32))\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    x = x.to(device) \n",
    "    y = y.to(device)\n",
    "    print(net.forward(x, y).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87ddb4-1cad-4636-be64-0e46736a2f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc97f74-7331-4d44-bf6b-a230017c1f7d",
   "metadata": {},
   "source": [
    "# 画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bc7040d7-59fb-4b60-b29a-e5e0dfe3d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5f9b2d7d-c751-4a38-ac73-9bb8de21d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_path = dict_toml[\"path\"][\"cascades\"] +\"/haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "def3de37-4e70-4726-9332-7679d2ca6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"000001.jpg\"\n",
    "image_path = dict_toml[\"path\"][\"dataset\"][\"image\"]+\"/img_align_celeba/\" + file\n",
    "output_path = os.getcwd()+\"/\" + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "54e32e75-1ba1-4e6c-a874-94fcdcd3894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dict_toml[\"path\"][\"dataset\"][\"image\"]+\"/img_align_celeba/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685cb45-dc61-43bb-8f0b-435c9bccfb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(os.path.join(dir_path, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5880391c-5ffa-44e9-8827-e9b095f5dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4ac30976-bb77-4a33-b3a0-af9adc6188cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=2, minSize=(30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4d68fb6-c00e-4152-9bce-bedd0445224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b484acf-a0a4-4f19-b250-868644835842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検出した場合\n",
    "if len(facerect) > 0:\n",
    "\n",
    "    #検出した顔を囲む矩形の作成\n",
    "    for rect in facerect:\n",
    "        cv2.rectangle(image, tuple([40,0]),tuple([100,100]), color, thickness=2)\n",
    "\n",
    "    #認識結果の保存\n",
    "    cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f00c7767-f890-453c-b945-394603f84eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 178)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "20bf304e-ec7d-42bd-bd44-b7c9c6dc01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannaka = np.flip(np.ceil(facerect[0][0:2]+facerect[0][2:4]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "733e574e-82e4-4d6d-af03-97abbeb66431",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = image.shape[:2] - np.flip(np.ceil(facerect[0][0:2]+facerect[0][2:4]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1672051-1deb-4369-80c8-f21667c35bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.minimum(mannaka, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9c4994f1-1182-468b-9d4c-cb0eedeae958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a1afb02a-fc82-4808-82e1-2ca4c5ee7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = mannaka - m.min()\n",
    "bot = mannaka + m.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2d6148b3-b635-435a-8159-055ad214f174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.,  2.])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91ed6b-1330-445c-be80-30e21b598af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0df01895-d088-436e-bcf3-ce6cff70ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = image[int(top[0]):int(bot[0]),int(top[1]):int(bot[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "29bf8bd0-0b81-43b8-929c-355f9eb81420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 176, 3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6df4ba85-20ea-4d31-84ae-d6bc1f57d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.resize(img2, dsize=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d27d262e-20d1-4b54-b29d-fa92095177c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(output_path, img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd01061-6b39-4c6d-a233-116c4b7391b5",
   "metadata": {},
   "source": [
    "# ファイル操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b5ae538-7a62-4ac9-82d4-3cdb6f807a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cascades': '/home/jun/Documents/CMVC/cmvc/cascades', 'dataset': {'image': '/mnt/c/Users/pkmae/github/dataset/celebA'}}\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "\n",
    "dict_toml = toml.load(open('cmvc/config.toml'))\n",
    "print(dict_toml[\"path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ccc91fc-e809-4abe-bf4c-6daf3da55011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jun/Documents/CMVC/cmvc/cascades'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath(\"cmvc/cascades\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
